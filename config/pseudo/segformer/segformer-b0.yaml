logdir: /data/data/landset30/newmodels_building/segformer/b0/
gpus: [0]
distributed: true
fp16: false
lrank: 0

# define model
model:
  architecture: segformer_b0
  model_scale: 1
  preweightpath: /data/data
  init_params:
    in_channels: 3
    classes: 1
    activation: sigmoid

tta: False

data:
  
#  tv_path: /data/data/landset30/Unet_bifpn/new512_128/pixel_ratio_8000.csv
  # datasets
  train_dataset:
    name: SegDataset
    init_params:
      images_dir: /data/data/landset30/Unet_bifpn/tmp/train/image
      masks_dir: /data/data/landset30/Unet_bifpn/tmp/train/mask
      transform_name: train_transform_1

  valid_dataset:
    name: SegDataset
    init_params:
      images_dir: /data/data/landset30/Unet_bifpn/tmp/test/image
      masks_dir: /data/data/landset30/Unet_bifpn/tmp/test/mask
      transform_name: test_transform_1

  test_dataset:
    name: SegDataset
    init_params:
      images_dir: /data/data/landset30/Unet_bifpn/tmp/test/image
      masks_dir: /data/data/landset30/Unet_bifpn/tmp/test/mask
      transform_name: test_transform_1

  pseudo_dataset:
    name: PseudoDataset
    init_params:
      images_dir: /data/data/landset30/Unet_bifpn/tmp/test/image
      masks_dir: /data/data/landset30/Unet_bifpn/tmp/test/mask
      pse_images_dir: /data/data/landset30/Unet_bifpn/tmp/test/image
      pse_masks_dir: /data/data/landset30/Unet_bifpn/tmp/pseudo/mask
      transform_name: test_transform_1

  # loaders
  train_dataloader:
    batch_size: 10
    drop_last: true
    pin_memory: true
    num_workers: 0

  valid_dataloader:
    batch_size: 10
    shuffle: false
    drop_last: false
    pin_memory: true
    num_workers: 0

  test_dataloader:
    batch_size: 10
    shuffle: false
    drop_last: false
    pin_memory: false
    num_workers: 0

  pseudo_dataloader:
    batch_size: 10
    drop_last: true
    pin_memory: true
    num_workers: 0

training:

  losses:
    mask:
      name: BCEDiceLoss
      init_params:

  metrics:
    mask:
      - name: MicroF1
        init_params:

  optimizer:
    name: adamw
    init_params:
      lr: 0.001

  scheduler:
    name: WarmupPolyLR
    init_params:
      epochs: 60

  fit:
    epochs: 40
    accumulation_steps: 4
    verbose: true

  callbacks: []

  runner:
    model_output_keys: mask


logging:
  save_top: 10
